{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGD1_6pQcdwz"
   },
   "source": [
    "# **Speech Recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1uy-Tcu3TrP",
    "outputId": "35e98453-052d-42ed-a376-0d7c2a4ef1c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Jumlah data: 201\n",
      "Shape fitur: (201, 123)\n",
      "Mapping speaker: {'putra': np.int64(0), 'tory': np.int64(1)}\n",
      "\n",
      "=== EKSPERIMEN 1: PCA 100 components ===\n",
      "Akurasi: 0.975609756097561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        19\n",
      "           1       1.00      0.95      0.98        22\n",
      "\n",
      "    accuracy                           0.98        41\n",
      "   macro avg       0.97      0.98      0.98        41\n",
      "weighted avg       0.98      0.98      0.98        41\n",
      "\n",
      "\n",
      "=== FEATURE SELECTION: Information Gain ===\n",
      "\n",
      "=== EKSPERIMEN 2: Seleksi Fitur (IG top-30) ===\n",
      "Akurasi: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           1.00        41\n",
      "   macro avg       1.00      1.00      1.00        41\n",
      "weighted avg       1.00      1.00      1.00        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "#   SPEECH RECOGNITION PIPELINE\n",
    "#   MULTI-LABEL: buka / tutup + speaker\n",
    "#   Full features (156) → PCA → Classification\n",
    "#   + Feature Selection (Information Gain)\n",
    "# ===============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# -----------------------------------------------\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DATASET_DIR = \"/content/drive/MyDrive/11. Speech Recognition/dataset_renamed\"  # ganti path sesuai lokasi dataset\n",
    "LABEL_FILE   = \"/content/drive/MyDrive/11. Speech Recognition/label.csv\"\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 1. LOAD LABEL FILE\n",
    "# ===============================================================\n",
    "labels = pd.read_csv(LABEL_FILE)\n",
    "print(\"Jumlah data:\", len(labels))\n",
    "\n",
    "# ===============================================================\n",
    "# 2. FEATURE EXTRACTION (TOTAL ±156)\n",
    "# ===============================================================\n",
    "def extract_features(path):\n",
    "    \"\"\"Ekstraksi fitur statistical, temporal, spectral (±156 fitur).\"\"\"\n",
    "    y, sr = librosa.load(path, sr=None)\n",
    "\n",
    "    # ===== TEMPORAL FEATURES =====\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "    energy = np.mean(y ** 2)\n",
    "    rms = np.mean(librosa.feature.rms(y=y))\n",
    "\n",
    "    # ===== SPECTRAL FEATURES =====\n",
    "    spec_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    spec_bw = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    spec_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "    spec_flux = np.mean(np.diff(np.abs(librosa.stft(y))).mean(axis=1))\n",
    "\n",
    "    # ===== MFCC 20 + ΔMFCC 20 + ΔΔ MFCC 20 (total 60) =====\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "    mfcc_delta_mean = np.mean(mfcc_delta, axis=1)\n",
    "\n",
    "    mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    mfcc_delta2_mean = np.mean(mfcc_delta2, axis=1)\n",
    "\n",
    "    # ===== CHROMA (12), MEL (40) =====\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_mean = np.mean(chroma, axis=1)\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    mel_mean = np.mean(mel, axis=1)\n",
    "\n",
    "    # ===== STATISTICAL FEATURES =====\n",
    "    mean = np.mean(y)\n",
    "    std = np.std(y)\n",
    "    skew = pd.Series(y).skew()\n",
    "    kurtosis = pd.Series(y).kurt()\n",
    "\n",
    "    features = np.hstack([\n",
    "        zcr, energy, rms,\n",
    "        spec_centroid, spec_bw, spec_rolloff, spec_flux,\n",
    "        mfcc_mean, mfcc_delta_mean, mfcc_delta2_mean,\n",
    "        chroma_mean, mel_mean[:40],   # mel truncated to 40 for 156 total\n",
    "        mean, std, skew, kurtosis\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 3. LOAD ALL FEATURES\n",
    "# ===============================================================\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = []\n",
    "y1 = []  # buka/tutup\n",
    "y2 = []  # speaker\n",
    "\n",
    "le_speaker = LabelEncoder()\n",
    "labels['speaker_enc'] = le_speaker.fit_transform(labels['speaker'])  # tory/putra → 0/1\n",
    "\n",
    "for i, row in labels.iterrows():\n",
    "    file_path = os.path.join(DATASET_DIR, row['filename'])\n",
    "    feats = extract_features(file_path)\n",
    "    X.append(feats)\n",
    "\n",
    "    y1.append(1 if row['command'] == \"buka\" else 0)\n",
    "    y2.append(row['speaker_enc'])  # encode speaker menjadi angka\n",
    "\n",
    "X = np.array(X)\n",
    "y1 = np.array(y1)\n",
    "y2 = np.array(y2)\n",
    "\n",
    "print(\"Shape fitur:\", X.shape)\n",
    "print(\"Mapping speaker:\", dict(zip(le_speaker.classes_, le_speaker.transform(le_speaker.classes_))))\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 4. SPLIT DATA\n",
    "# ===============================================================\n",
    "X_train, X_test, y_train_cmd, y_test_cmd = train_test_split(\n",
    "    X, y1, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ===============================================================\n",
    "# 5. NORMALISASI\n",
    "# ===============================================================\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# ===============================================================\n",
    "# 6. EXPERIMENT 1 — FULL FEATURES → PCA → CLASSIFIER\n",
    "# ===============================================================\n",
    "print(\"\\n=== EKSPERIMEN 1: PCA 100 components ===\")\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "clf1 = SVC(kernel=\"rbf\")\n",
    "clf1.fit(X_train_pca, y_train_cmd)\n",
    "pred1 = clf1.predict(X_test_pca)\n",
    "\n",
    "print(\"Akurasi:\", accuracy_score(y_test_cmd, pred1))\n",
    "print(classification_report(y_test_cmd, pred1))\n",
    "\n",
    "# ===============================================================\n",
    "# 7. FEATURE SELECTION (INFORMATION GAIN)\n",
    "# ===============================================================\n",
    "print(\"\\n=== FEATURE SELECTION: Information Gain ===\")\n",
    "\n",
    "IG = mutual_info_classif(X_train_scaled, y_train_cmd)\n",
    "ranking = np.argsort(IG)[::-1]  # urut dari IG tertinggi ke rendah\n",
    "\n",
    "TOP_K = 30  # jumlah fitur terbaik (silakan ubah)\n",
    "selected_idx = ranking[:TOP_K]\n",
    "\n",
    "X_train_sel = X_train_scaled[:, selected_idx]\n",
    "X_test_sel  = X_test_scaled[:, selected_idx]\n",
    "\n",
    "# ===============================================================\n",
    "# 8. EXPERIMENT 2 — IG SELECTED FEATURES → CLASSIFIER\n",
    "# ===============================================================\n",
    "print(\"\\n=== EKSPERIMEN 2: Seleksi Fitur (IG top-30) ===\")\n",
    "\n",
    "clf2 = SVC(kernel=\"rbf\")\n",
    "clf2.fit(X_train_sel, y_train_cmd)\n",
    "pred2 = clf2.predict(X_test_sel)\n",
    "\n",
    "print(\"Akurasi:\", accuracy_score(y_test_cmd, pred2))\n",
    "print(classification_report(y_test_cmd, pred2))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}